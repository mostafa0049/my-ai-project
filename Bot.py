import pandas as pd

def update_mega_database():
    # Ø±ÙˆØ§Ø¨Ø· Ù„Ù…ØµØ§Ø¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ© Ø¶Ø®Ù…Ø© ØªØºØ·ÙŠ Ù…Ø¹Ø¸Ù… Ø¯ÙˆØ±ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù„Ù…
    urls = [
        "https://www.football-data.co.uk/mmz4281/2425/E0.csv", # Ø¥Ù†Ø¬Ù„ØªØ±Ø§
        "https://www.football-data.co.uk/mmz4281/2425/SP1.csv", # Ø¥Ø³Ø¨Ø§Ù†ÙŠØ§
        "https://www.football-data.co.uk/mmz4281/2425/I1.csv",  # Ø¥ÙŠØ·Ø§Ù„ÙŠØ§
        "https://www.football-data.co.uk/mmz4281/2425/D1.csv",  # Ø£Ù„Ù…Ø§Ù†ÙŠØ§
        "https://raw.githubusercontent.com/jokecamp/FootballData/master/nfl/nfl_2023.csv", # Ù…Ø«Ø§Ù„ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        "https://www.football-data.co.uk/mmz4281/2425/F1.csv"   # ÙØ±Ù†Ø³Ø§
    ]
    
    all_frames = []
    print("ğŸŒ Ø¬Ø§Ø±ÙŠ Ø§Ø¬ØªÙŠØ§Ø­ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©...")

    for url in urls:
        try:
            df = pd.read_csv(url)
            # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©: Ø§Ù„Ø¯ÙˆØ±ÙŠØŒ Ø§Ù„Ù…Ø¶ÙŠÙØŒ Ø§Ù„Ø¶ÙŠÙØŒ Ø£Ù‡Ø¯Ø§Ù Ù‡Ù€ØŒ Ø£Ù‡Ø¯Ø§Ù Ø¶ØŒ Ø§Ù„Ù†ØªÙŠØ¬Ø©ØŒ Ø§Ù„ØªØ§Ø±ÙŠØ®
            # Ø³Ù†Ù‚ÙˆÙ… Ø¨Ù…Ø­Ø§ÙˆÙ„Ø© Ø°ÙƒÙŠØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯ÙˆØ±ÙŠ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù†ÙØ³Ù‡
            league_name = url.split('/')[-1].split('.')[0]
            
            temp_df = pd.DataFrame()
            temp_df['Div'] = [league_name] * len(df)
            temp_df['Home'] = df['HomeTeam']
            temp_df['Away'] = df['AwayTeam']
            temp_df['HG'] = df['FTHG']
            temp_df['AG'] = df['FTAG']
            temp_df['Res'] = df['FTR']
            temp_df['Date'] = df['Date']
            
            all_frames.append(temp_df)
        except Exception as e:
            print(f"âš ï¸ ØªØ®Ø·ÙŠ Ù…ØµØ¯Ø± Ø¨Ø³Ø¨Ø¨: {e}")

    if all_frames:
        final_db = pd.concat(all_frames, ignore_index=True)
        final_db.to_csv('updated_matches.csv', index=False)
        print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù€ {len(final_db)} Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ù† Ù…Ø®ØªÙ„Ù Ø§Ù„Ù‚Ø§Ø±Ø§Øª!")

if __name__ == "__main__":
    update_mega_database()
